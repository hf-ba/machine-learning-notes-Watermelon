# 第三章 线性模型
## 3.1 基本形式
本章与传统统计学中的线性模型有高度重复之处，区别是传统统计学更看重假设检验的内容，机器学习中则引入了诸多新方法。
基本形式为，其特点是具有较好的可解释性：

$$
f(x) = w^{T}x+b
$$

## 3.2 线性回归

- 对于离散值，可以进行连续化，类似于计量经济学中的dummy variable
- 线性回归的解就是OLS的求解，书上给出的解与正规方程组等价
- 对于多元线性回归，其解法与统计学相同，将矩阵写成内积形式后展开并求导，其结果如下

![图片](https://github.com/user-attachments/assets/0b0dcef0-333d-4d08-b087-63c32748fb1e)

- 如果矩阵不满秩，则可以引入正则化（岭回归加入系数平方和，lasso加入系数绝对值，弹性网络都加入）
- GLM：将线性模型拓展为非线性模型，对于对数线性模型来说，其含义为x增长1单位，y增长1%（回顾计量经济学内容）

## 3.3 对数几率回归

基本思想：将回归转化为分类，实值转化为0/1值
使用函数：Sigmoid，其推导与含义如下

![image](https://github.com/user-attachments/assets/fd86265c-0f77-48db-9c19-0166d8571a17)

实际上就是用线性回归来预测真实的标记的**对数几率**，在实际中还需要设定决策边界来划分正反例。并且该方法是直接对分类可能性进行建模，无需事先假设数据分布，这样就避免了假设分布不准确所带来的问题。

在课本上还讲解了确定回归参数的方法，具体思路为：

- 将y视为后验概率估计后，求解MLE，可以得到如下结果。需要注意的是虽然求解MLE过程本身很简单，但是需要注意其细节

![image](https://github.com/user-attachments/assets/c15bb5d3-80aa-4005-a1c2-9f94f190474e)

- 该函数为凸（可以用海塞矩阵证明），可以用最优化理论解决（此处具体由最优化理论解决，不做深入探讨）

## 3.4 线性判别分析（LDA）












